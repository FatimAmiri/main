
<!DOCTYPE html>

<html lang="en">
<head>
<title>compas -- a computational framework for research in architecture and structures</title>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<meta content="Tom Van Mele" name="author"/>
<meta content="compas is a computational framework for research in architecture and structures." name="description"/>
<link crossorigin="anonymous" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" rel="stylesheet"/>
<link href="/css/github.css" rel="stylesheet" type="text/css"/>
<link href="/css/compas.css" rel="stylesheet" type="text/css"/>
<link href="/css/compas-reference.css" rel="stylesheet" type="text/css"/>
<script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
</head>
<body data-spy="scroll" data-target="#compas-localnav">
<header class="navbar navbar-expand navbar-dark bg-dark compas-navbar">
<a class="navbar-brand" href="/">compas</a>
<ul class="navbar-nav">
<li class="nav-item">
<a class="nav-link active" href="/compas">Main library</a>
</li>
<li class="nav-item">
<a class="nav-link" href="/packages">Additional Packages</a>
</li>
</ul>
</header>
<div class="container-fluid compas-container">
<div class="row flex-xl-nowrap">
<main class="col-12 col-md-9 col-xl-8 compas-content" role="main">
<nav class="breadcrumb">
<a class="breadcrumb-item" href="https://compas-dev.github.io/">compas</a>
<a class="breadcrumb-item" href="https://compas-dev.github.io/compas/index.html">main library</a>
<a accesskey="U" class="breadcrumb-item" href="../../../index.html">module code</a>
</nav>
<h1>Source code for compas.hpc.cuda._array</h1><div class="highlight"><pre><code class="language-python border rounded">
<span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">array</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">float32</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">float64</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">complex64</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">pycuda</span>
    <span class="kn">import</span> <span class="nn">pycuda.autoinit</span>
    <span class="kn">import</span> <span class="nn">pycuda.curandom</span>
    <span class="kn">import</span> <span class="nn">pycuda.gpuarray</span>
<span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">skcuda</span>
    <span class="kn">import</span> <span class="nn">skcuda.autoinit</span>
    <span class="kn">import</span> <span class="nn">skcuda.linalg</span>
<span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">pass</span>


<span class="n">__author__</span>     <span class="o">=</span> <span class="p">[</span><span class="s1">'Andrew Liew &lt;liew@arch.ethz.ch&gt;'</span><span class="p">]</span>
<span class="n">__copyright__</span>  <span class="o">=</span> <span class="s1">'Copyright 2016, Block Research Group - ETH Zurich'</span>
<span class="n">__license__</span>    <span class="o">=</span> <span class="s1">'MIT License'</span>
<span class="n">__email__</span>      <span class="o">=</span> <span class="s1">'liew@arch.ethz.ch'</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">'cuda_diag'</span><span class="p">,</span>
    <span class="s1">'cuda_eye'</span><span class="p">,</span>
    <span class="s1">'cuda_get'</span><span class="p">,</span>
    <span class="s1">'cuda_give'</span><span class="p">,</span>
    <span class="s1">'cuda_ones'</span><span class="p">,</span>
    <span class="s1">'cuda_random'</span><span class="p">,</span>
    <span class="s1">'cuda_real'</span><span class="p">,</span>
    <span class="s1">'cuda_reshape'</span><span class="p">,</span>
    <span class="s1">'cuda_flatten'</span><span class="p">,</span>
    <span class="s1">'cuda_tile'</span><span class="p">,</span>
    <span class="s1">'cuda_zeros'</span><span class="p">,</span>
<span class="p">]</span>


<div class="viewcode-block" id="cuda_diag"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_diag.html#compas.hpc.cuda_diag">[docs]</a><span class="k">def</span> <span class="nf">cuda_diag</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="sd">""" Construct or extract GPUArray diagonal.</span>

<span class="sd">    Note:</span>
<span class="sd">        If a is 1D, a GPUArray is constructed, if 2D, the diagonal is extracted.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        a (gpu): GPUArray (1D or 2D).</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: GPUArray with inserted diagonal, or vector of diagonal.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_diag(cuda_give([1, 2, 3]))</span>
<span class="sd">        array([[ 1.,  0.,  0.],</span>
<span class="sd">               [ 0.,  2.,  0.],</span>
<span class="sd">               [ 0.,  0.,  3.]])</span>
<span class="sd">        &gt;&gt;&gt; b = cuda_diag(a)</span>
<span class="sd">        array([ 1.,  2.,  3.])</span>
<span class="sd">        &gt;&gt;&gt; type(b)</span>
<span class="sd">        &lt;class 'pycuda.gpuarray.GPUArray'&gt;</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">skcuda</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="p">)</span></div>


<div class="viewcode-block" id="cuda_eye"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_eye.html#compas.hpc.cuda_eye">[docs]</a><span class="k">def</span> <span class="nf">cuda_eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">bit</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
    <span class="sd">""" Create GPUArray identity matrix (ones on diagonal) of size (n x n).</span>

<span class="sd">    Parameters:</span>
<span class="sd">        n (int): Size of identity matrix (n x n).</span>
<span class="sd">        bit (int): 32 or 64 for corresponding float precision.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: Identity matrix (n x n) as GPUArray.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_eye(3)</span>
<span class="sd">        array([[ 1.,  0.,  0.],</span>
<span class="sd">               [ 0.,  1.,  0.],</span>
<span class="sd">               [ 0.,  0.,  1.]])</span>
<span class="sd">        &gt;&gt;&gt; type(a)</span>
<span class="sd">        &lt;class 'pycuda.gpuarray.GPUArray'&gt;</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">bit</span> <span class="o">==</span> <span class="mi">32</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">skcuda</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">bit</span> <span class="o">==</span> <span class="mi">64</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">skcuda</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float64</span><span class="p">)</span></div>


<div class="viewcode-block" id="cuda_flatten"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_flatten.html#compas.hpc.cuda_flatten">[docs]</a><span class="k">def</span> <span class="nf">cuda_flatten</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="sd">""" Flatten/ravel out a GPUArray.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        a (gpu): GPUArray.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: 1D version of original GPUArray.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_flatten(cuda_eye(3))</span>
<span class="sd">        array([ 1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.])</span>
<span class="sd">        &gt;&gt;&gt; type(a)</span>
<span class="sd">        &lt;class 'pycuda.gpuarray.GPUArray'&gt;</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span></div>


<div class="viewcode-block" id="cuda_get"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_get.html#compas.hpc.cuda_get">[docs]</a><span class="k">def</span> <span class="nf">cuda_get</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="sd">""" Get back GPUArray from GPU memory as NumPy array.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        a (gpu): Data on the GPU memory to retrieve.</span>

<span class="sd">    Returns:</span>
<span class="sd">        array: The GPUArray returned to RAM as NumPy array.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_give([1, 2, 3], bit=64)</span>
<span class="sd">        &gt;&gt;&gt; b = cuda_get(a)</span>
<span class="sd">        array([ 1.,  2.,  3.])</span>
<span class="sd">        &gt;&gt;&gt; type(b)</span>
<span class="sd">        &lt;class 'numpy.ndarray'&gt;</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">get</span><span class="p">()</span></div>


<div class="viewcode-block" id="cuda_give"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_give.html#compas.hpc.cuda_give">[docs]</a><span class="k">def</span> <span class="nf">cuda_give</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">bit</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s1">'real'</span><span class="p">):</span>
    <span class="sd">""" Give a list or an array to GPU memory.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        a (array, list): Data to send to the GPU memory.</span>
<span class="sd">        bit (int): 32 or 64 for corresponding float precision.</span>
<span class="sd">        type (str): 'real' or 'complex'.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: GPUArray of input array.</span>

<span class="sd">    Creates and sends an array of float32 or float64 dtype from RAM to GPU</span>
<span class="sd">    memory.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_give([[1, 2, 3], [4, 5, 6]], bit=64)</span>
<span class="sd">        array([[ 1.,  2.,  3.],</span>
<span class="sd">               [ 4.,  5.,  6.]])</span>
<span class="sd">        &gt;&gt;&gt; type(a)</span>
<span class="sd">        &lt;class 'pycuda.gpuarray.GPUArray'&gt;</span>
<span class="sd">        &gt;&gt;&gt; a.shape</span>
<span class="sd">        (2, 3)</span>
<span class="sd">        &gt;&gt;&gt; a.dtype</span>
<span class="sd">        dtype('float64')</span>
<span class="sd">        &gt;&gt;&gt; a.reshape((1, 6))</span>
<span class="sd">        array([[ 1.,  2.,  3.,  4.,  5.,  6.]])</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s1">'real'</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">bit</span> <span class="o">==</span> <span class="mi">32</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">pycuda</span><span class="o">.</span><span class="n">gpuarray</span><span class="o">.</span><span class="n">to_gpu</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">bit</span> <span class="o">==</span> <span class="mi">64</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">pycuda</span><span class="o">.</span><span class="n">gpuarray</span><span class="o">.</span><span class="n">to_gpu</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">float64</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s1">'complex'</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">bit</span> <span class="o">==</span> <span class="mi">32</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Complex numbers in 32 bit are not supported'</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">bit</span> <span class="o">==</span> <span class="mi">64</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">pycuda</span><span class="o">.</span><span class="n">gpuarray</span><span class="o">.</span><span class="n">to_gpu</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">complex64</span><span class="p">))</span></div>


<span class="k">def</span> <span class="nf">cuda_imag</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="sd">""" Return the imaginary parts of GPUArray.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        a (gpu): Complex GPUArray.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: Real parts of the input GPUArray.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; cuda_imag(cuda_give([1 + 2.j, 2 - 4.j], type='complex'))</span>
<span class="sd">        array([ 2., -4.], dtype=float32)</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">imag</span>


<div class="viewcode-block" id="cuda_ones"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_ones.html#compas.hpc.cuda_ones">[docs]</a><span class="k">def</span> <span class="nf">cuda_ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">bit</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
    <span class="sd">""" Create GPUArray of ones directly on GPU memory.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        shape (tuple): Dimensions of the GPUArray.</span>
<span class="sd">        bit (int): 32 or 64 for corresponding float precision.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: GPUArray of ones.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_ones((3, 2), bit=64)</span>
<span class="sd">        array([[ 1.,  1.],</span>
<span class="sd">               [ 1.,  1.],</span>
<span class="sd">               [ 1.,  1.]])</span>
<span class="sd">        &gt;&gt;&gt; type(a)</span>
<span class="sd">        &lt;class 'pycuda.gpuarray.GPUArray'&gt;</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">bit</span> <span class="o">==</span> <span class="mi">32</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">skcuda</span><span class="o">.</span><span class="n">misc</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bit</span> <span class="o">==</span> <span class="mi">64</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">skcuda</span><span class="o">.</span><span class="n">misc</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">float64</span><span class="p">)</span></div>


<div class="viewcode-block" id="cuda_random"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_random.html#compas.hpc.cuda_random">[docs]</a><span class="k">def</span> <span class="nf">cuda_random</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">bit</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
    <span class="sd">""" Create random values in the range [0, 1] as GPUArray.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        shape (tuple): Size of the random array.</span>
<span class="sd">        bit (int): 32 or 64 for corresponding float precision.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: Random floats from 0 to 1 in GPUArray.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_random((2, 2), bit=64)</span>
<span class="sd">        array([[ 0.80916596,  0.82687163],</span>
<span class="sd">               [ 0.03921388,  0.44197764]])</span>
<span class="sd">        &gt;&gt;&gt; type(a)</span>
<span class="sd">        &lt;class 'pycuda.gpuarray.GPUArray'&gt;</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">bit</span> <span class="o">==</span> <span class="mi">32</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pycuda</span><span class="o">.</span><span class="n">curandom</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">float32</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">bit</span> <span class="o">==</span> <span class="mi">64</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pycuda</span><span class="o">.</span><span class="n">curandom</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">float64</span><span class="p">)</span></div>


<div class="viewcode-block" id="cuda_real"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_real.html#compas.hpc.cuda_real">[docs]</a><span class="k">def</span> <span class="nf">cuda_real</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="sd">""" Return the real parts of GPUArray.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        a (gpu): Complex GPUArray.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: Real parts of the input GPUArray.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; cuda_real(cuda_give([1 + 2.j, 2 - 4.j], type='complex'))</span>
<span class="sd">        array([ 1.,  2.], dtype=float32)</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">real</span></div>


<div class="viewcode-block" id="cuda_reshape"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_reshape.html#compas.hpc.cuda_reshape">[docs]</a><span class="k">def</span> <span class="nf">cuda_reshape</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="sd">""" Reshape a GPUArray.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        a (gpu): GPUArray.</span>
<span class="sd">        shape (tuple): Dimension of new reshaped GPUArray.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: Reshaped GPUArray.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_reshape(cuda_give([[1, 2], [3, 4]]), (4, 1))</span>
<span class="sd">        array([[ 1.],</span>
<span class="sd">               [ 2.],</span>
<span class="sd">               [ 3.],</span>
<span class="sd">               [ 4.]])</span>
<span class="sd">        &gt;&gt;&gt; type(a)</span>
<span class="sd">        &lt;class 'pycuda.gpuarray.GPUArray'&gt;</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">cuda_squeeze</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="sd">""" Removes dimensions of length 1 from GPUArray.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        a (gpu): The GPUArray to squeeze.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: Squeezed GPUArray.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_squeeze(cuda_give([[1], [2]]))</span>
<span class="sd">        array([ 1.,  2.])</span>
<span class="sd">        &gt;&gt;&gt; type(a)</span>
<span class="sd">        &lt;class 'pycuda.gpuarray.GPUArray'&gt;</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>


<div class="viewcode-block" id="cuda_tile"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_tile.html#compas.hpc.cuda_tile">[docs]</a><span class="k">def</span> <span class="nf">cuda_tile</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="sd">""" Horizontally and vertically tile a GPUArray.</span>

<span class="sd">    Notes:</span>
<span class="sd">        May be slow for large tiling shapes as For loops are used.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        a (gpu): GPUArray to tile.</span>
<span class="sd">        shape (tuple): Number of vertical and horizontal tiles.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: Tiled GPUArray.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_tile(cuda_give([[1, 2], [3, 4]]), (2, 2))</span>
<span class="sd">        array([[ 1.,  2.,  1.,  2.],</span>
<span class="sd">               [ 3.,  4.,  3.,  4.],</span>
<span class="sd">               [ 1.,  2.,  1.,  2.],</span>
<span class="sd">               [ 3.,  4.,  3.,  4.]])</span>
<span class="sd">        &gt;&gt;&gt; type(a)</span>
<span class="sd">        &lt;class 'pycuda.gpuarray.GPUArray'&gt;</span>

<span class="sd">    """</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">cuda_zeros</span><span class="p">((</span><span class="n">m</span> <span class="o">*</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">m</span><span class="p">:</span><span class="n">i</span> <span class="o">*</span> <span class="n">m</span> <span class="o">+</span> <span class="n">m</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">a</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">cuda_zeros</span><span class="p">((</span><span class="n">m</span> <span class="o">*</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n</span> <span class="o">*</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">c</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">*</span> <span class="n">n</span><span class="p">:</span><span class="n">i</span> <span class="o">*</span> <span class="n">n</span> <span class="o">+</span> <span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>
    <span class="k">return</span> <span class="n">c</span></div>


<div class="viewcode-block" id="cuda_zeros"><a class="viewcode-back" href="../../../../reference/generated/compas.hpc.cuda_zeros.html#compas.hpc.cuda_zeros">[docs]</a><span class="k">def</span> <span class="nf">cuda_zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">bit</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
    <span class="sd">""" Create GPUArray of zeros directly on GPU memory.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        shape (tuple): Dimensions of the GPUArray.</span>
<span class="sd">        bit (int): 32 or 64 for corresponding float precision.</span>

<span class="sd">    Returns:</span>
<span class="sd">        gpu: GPUArray of zeros.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = cuda_zeros((3, 2), bit=64)</span>
<span class="sd">        array([[ 0.,  0.],</span>
<span class="sd">               [ 0.,  0.],</span>
<span class="sd">               [ 0.,  0.]])</span>
<span class="sd">        &gt;&gt;&gt; type(a)</span>
<span class="sd">        &lt;class 'pycuda.gpuarray.GPUArray'&gt;</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">pycuda</span><span class="o">.</span><span class="n">gpuarray</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">'float'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bit</span><span class="p">))</span></div>


<span class="c1"># ==============================================================================</span>
<span class="c1"># Debugging</span>
<span class="c1"># ==============================================================================</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">cuda_give</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">bit</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s1">'complex'</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">cuda_ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">bit</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">cuda_random</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">bit</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">cuda_real</span><span class="p">(</span><span class="n">cuda_give</span><span class="p">([</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">2.</span><span class="n">j</span><span class="p">,</span> <span class="mi">2</span> <span class="o">-</span> <span class="mf">4.</span><span class="n">j</span><span class="p">],</span> <span class="nb">type</span><span class="o">=</span><span class="s1">'complex'</span><span class="p">))</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">cuda_zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">bit</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">cuda_eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">cuda_diag</span><span class="p">(</span><span class="n">cuda_give</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">cuda_tile</span><span class="p">(</span><span class="n">cuda_give</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">cuda_squeeze</span><span class="p">(</span><span class="n">cuda_give</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]))</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">cuda_imag</span><span class="p">(</span><span class="n">cuda_give</span><span class="p">([</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">2.</span><span class="n">j</span><span class="p">,</span> <span class="mi">2</span> <span class="o">-</span> <span class="mf">4.</span><span class="n">j</span><span class="p">],</span> <span class="n">bit</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s1">'complex'</span><span class="p">))</span>
</code></pre></div>
<nav class="compas-sideways">
</nav>
</main>
<div class="col-12 col-md-3 col-xl-2 compas-sidebar" role="navigation">
<div class="navbar-light">
<form action="../../../../search.html" class="d-flex compas-searchbox" id="" method="get">
<input class="form-control" name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
<button aria-controls="compas-navigation" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler d-md-none compas-navigation-toggler" data-target="#compas-navigation" data-toggle="collapse" type="button">
<span class="navbar-toggler-icon"></span>
</button>
</form>
<div class="navbar-expand-md">
<div class="collapse navbar-collapse compas-navigation" id="compas-navigation">
<ul class="nav flex-column">
<li class="nav-item"><a class="nav-link reference internal" href="../../../../overview.html">Overview</a></li>
<li class="nav-item"><a class="nav-link reference internal" href="../../../../examples.html">Examples</a></li>
<li class="nav-item"><a class="nav-link reference internal" href="../../../../tutorial.html">Tutorial</a></li>
<li class="nav-item"><a class="nav-link reference internal" href="../../../../reference.html">Reference</a></li>
<li class="nav-item"><a class="nav-link reference internal" href="../../../../workshops.html">Workshops</a></li>
</ul>
</div>
</div>
</div>
</div>
<div class="d-none d-xl-block col-xl-2 compas-toc" role="toc">
</div>
</div>
</div>
<footer class="compas-footer">
            
                
                    © Copyright 2017, Block Research Group - ETH Zurich.
                
            

            
                Last updated on Oct 26, 2017.
            

            
                Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.5.1.
            
        </footer>
<script type="text/javascript">
var DOCUMENTATION_OPTIONS = {
    URL_ROOT:    '',
    VERSION:     '',
    COLLAPSE_INDEX: false,
    FILE_SUFFIX: '.html',
    HAS_SOURCE:  true,
    SOURCELINK_SUFFIX: '.txt'
};
            </script>
<script crossorigin="anonymous" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
<script crossorigin="anonymous" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js"></script>
<script crossorigin="anonymous" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.0.0/anchor.js"></script>
<script src="/static/underscore.js"></script>
<script src="/static/doctools.js"></script>
<script src="https://compas-dev.github.io/compas/static/searchtools_.js"></script>
<script>
                hljs.initHighlightingOnLoad();
                anchors.add();
            </script>
</body>
</html>